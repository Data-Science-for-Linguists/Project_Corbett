{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robert Corbett\n",
    "\n",
    "Reddit post exploration part 2\n",
    "\n",
    "This code is used to just find the number of posts I extracted from each subreddit. I have a large amount of data to choose from so I am only going to use a couple months of posts. The number of posts each subreddit has varies drastically. Some subreddits have hundreds of thousands of posts while some of a couple hundred. For the project, I want to use subreddits that have atleast 50,000 posts to work with.\n",
    "\n",
    "I also want to make sure the body of the posts are of a useful length.  Looking at the average lengths of posts, I decided to make sure that each post is atleast 150 characters.  \n",
    "\n",
    "In the end, I managed to extract 50,000 posts of atleast 150 characters long from 8 subreddits: Conservative, Libertarian, neoliberal, politics, worldnews, Android, boardgames and hockey.  They are saved as csv files on my local machine.  \n",
    "\n",
    "This code took about 5 hours to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by counting the number of lines in the json file for September, 2017.  I saved the total in a variable with the same name and printed the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of September, 2017\n",
      "Len of Android: 165509\n",
      "Len of Archaeology: 574\n",
      "Len of AskTrumpSupporters: 41290\n",
      "Len of boardgames: 61240\n",
      "Len of Conservative: 55766\n",
      "Len of DCcomics: 24647\n",
      "Len of food: 69709\n",
      "Len of Futurism: 197\n",
      "Len of geopolitics: 7313\n",
      "Len of gunpolitics: 4390\n",
      "Len of headphones: 29723\n",
      "Len of hockey: 199269\n",
      "Len of indie_rock: 491\n",
      "Len of indieheads: 35572\n",
      "Len of Libertarian: 103633\n",
      "Len of MarchAgainstTrump: 11761\n",
      "Len of neoliberal: 212190\n",
      "Len of NeverTrump: 180\n",
      "Len of photography: 36431\n",
      "Len of politics: 1390463\n",
      "Len of PoliticsWithoutTheBan: 0\n",
      "Len of seinfeld: 5277\n",
      "Len of The_Donald: 904159\n",
      "Len of worldnews: 777276\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/September_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of September, 2017\")\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the same for August, 2017 but added the totals to the totals for September and printed the totals for the month below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of August, 2017\n",
      "Len of Android: 143884\n",
      "Len of Archaeology: 805\n",
      "Len of AskTrumpSupporters: 45575\n",
      "Len of boardgames: 60254\n",
      "Len of Conservative: 66364\n",
      "Len of DCcomics: 27988\n",
      "Len of food: 68758\n",
      "Len of Futurism: 187\n",
      "Len of geopolitics: 6269\n",
      "Len of gunpolitics: 2836\n",
      "Len of headphones: 30372\n",
      "Len of hockey: 157833\n",
      "Len of indie_rock: 320\n",
      "Len of indieheads: 39867\n",
      "Len of Libertarian: 94092\n",
      "Len of MarchAgainstTrump: 19208\n",
      "Len of neoliberal: 184248\n",
      "Len of NeverTrump: 322\n",
      "Len of photography: 41420\n",
      "Len of politics: 1824215\n",
      "Len of PoliticsWithoutTheBan: 10\n",
      "Len of seinfeld: 4045\n",
      "Len of The_Donald: 1057483\n",
      "Len of worldnews: 741492\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/August_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of August, 2017\")\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = Android + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = Archaeology + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = AskTrumpSupporters + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = boardgames + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = Conservative + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = DCcomics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = food + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = Futurism + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = geopolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = gunpolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = headphones + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = hockey + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = indie_rock + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = indieheads + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = Libertarian + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = MarchAgainstTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = neoliberal + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = NeverTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = photography + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = politics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = PoliticsWithoutTheBan + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = seinfeld + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = The_Donald + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = worldnews + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for July was corrupted and I could not get the json entries to open.  So I skipped July and am going to use June instead.  I do not see skipping July causing any problems with the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of June, 2017\n",
      "Len of Android: 124963\n",
      "Len of Archaeology: 524\n",
      "Len of AskTrumpSupporters: 44644\n",
      "Len of boardgames: 63268\n",
      "Len of Conservative: 47492\n",
      "Len of DCcomics: 33775\n",
      "Len of food: 67223\n",
      "Len of Futurism: 161\n",
      "Len of geopolitics: 6086\n",
      "Len of gunpolitics: 3777\n",
      "Len of headphones: 26346\n",
      "Len of hockey: 486157\n",
      "Len of indie_rock: 250\n",
      "Len of indieheads: 39393\n",
      "Len of Libertarian: 83183\n",
      "Len of MarchAgainstTrump: 67415\n",
      "Len of neoliberal: 160842\n",
      "Len of NeverTrump: 327\n",
      "Len of photography: 40423\n",
      "Len of politics: 1818730\n",
      "Len of PoliticsWithoutTheBan: 0\n",
      "Len of seinfeld: 3882\n",
      "Len of The_Donald: 1158567\n",
      "Len of worldnews: 909968\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/June_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of June, 2017\")\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = Android + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = Archaeology + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = AskTrumpSupporters + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = boardgames + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = Conservative + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = DCcomics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = food + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = Futurism + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = geopolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = gunpolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = headphones + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = hockey + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = indie_rock + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = indieheads + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = Libertarian + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = MarchAgainstTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = neoliberal + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = NeverTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = photography + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = politics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = PoliticsWithoutTheBan + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = seinfeld + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = The_Donald + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = worldnews + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below I printed the totals for each subreddit for the three months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for both months\n",
      "Android: 434356\n",
      "Archaeology: 1903\n",
      "AskTrumpSupporters: 131509\n",
      "boardgames: 184762\n",
      "Conservative: 169622\n",
      "DCcomics: 86410\n",
      "food: 205690\n",
      "Futurism: 545\n",
      "geopolitics: 19668\n",
      "gunpolitics: 11003\n",
      "headphones: 86441\n",
      "hockey: 843259\n",
      "indie_rock: 1061\n",
      "indieheads: 114832\n",
      "Libertarian: 280908\n",
      "MarchAgainstTrump: 98384\n",
      "neoliberal: 557280\n",
      "NeverTrump: 829\n",
      "photography: 118274\n",
      "politics: 5033408\n",
      "PoliticsWithoutTheBan: 10\n",
      "seinfeld: 13204\n",
      "The_Donald: 3120209\n",
      "worldnews: 2428736\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of posts in each subreddit for both months\")\n",
    "print(\"Android: \" + str(Android))\n",
    "print(\"Archaeology: \" + str(Archaeology))\n",
    "print(\"AskTrumpSupporters: \" + str(AskTrumpSupporters))\n",
    "print(\"boardgames: \" + str(boardgames))\n",
    "print(\"Conservative: \" + str(Conservative))\n",
    "print(\"DCcomics: \" + str(DCcomics))\n",
    "print(\"food: \" + str(food))\n",
    "print(\"Futurism: \" + str(Futurism))\n",
    "print(\"geopolitics: \" + str(geopolitics))\n",
    "print(\"gunpolitics: \" + str(gunpolitics))\n",
    "print(\"headphones: \" + str(headphones))\n",
    "print(\"hockey: \" + str(hockey))\n",
    "print(\"indie_rock: \" + str(indie_rock))\n",
    "print(\"indieheads: \" + str(indieheads))\n",
    "print(\"Libertarian: \" + str(Libertarian))\n",
    "print(\"MarchAgainstTrump: \" + str(MarchAgainstTrump))\n",
    "print(\"neoliberal: \" + str(neoliberal))\n",
    "print(\"NeverTrump: \" + str(NeverTrump))\n",
    "print(\"photography: \" + str(photography))\n",
    "print(\"politics: \" + str(politics))\n",
    "print(\"PoliticsWithoutTheBan: \" + str(PoliticsWithoutTheBan))\n",
    "print(\"seinfeld: \" + str(seinfeld))\n",
    "print(\"The_Donald: \" + str(The_Donald))\n",
    "print(\"worldnews: \" + str(worldnews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, I want political subreddits, both with and without political biases.  So, for biased political subreddits, I am going to use \"Conservative\", \"Libertarian\" and \"neoliberal\".  For nonbiased political subreddits, I am going to use \"politics\" and \"worldnews\".  As a control, I will use non political subreddits.  I will use \"Android\", \"boardgames\" and \"hockey\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to find out the average length of posts.  Many of the posts are very short.  I want to use the longest posts I can while mantaining the 50,000 post goal.  Below, I calculated the average lengths and how many posts are greater than 50, 100, 150, 200, 250, and 300 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in Conservative     : 169622\n",
      "Average length of body              : 218.35662826755964\n",
      "number of posts over 50   characters: 122319\n",
      "number of posts over 100  characters: 91978\n",
      "number of posts over 150  characters: 69784\n",
      "number of posts over 200  characters: 54493\n",
      "number of posts over 250  characters: 43749\n",
      "number of posts over 300  characters: 35778\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(\"Number of posts in Conservative     : \" + str(num_posts))\n",
    "print(\"Average length of body              : \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50   characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150  characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300  characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in Libertarian      : 280908\n",
      "Average length of body              : 287.30290344169623\n",
      "number of posts over 50   characters: 227488\n",
      "number of posts over 100  characters: 177428\n",
      "number of posts over 150  characters: 139855\n",
      "number of posts over 200  characters: 112474\n",
      "number of posts over 250  characters: 92363\n",
      "number of posts over 300  characters: 77299\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(\"Number of posts in Libertarian      : \" + str(num_posts))\n",
    "print(\"Average length of body              : \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50   characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150  characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300  characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557280\n",
      "Average length of body: 153.20315281366638\n",
      "number of posts over 50  characters: 350206\n",
      "number of posts over 100  characters: 221754\n",
      "number of posts over 150 characters: 150061\n",
      "number of posts over 200  characters: 108318\n",
      "number of posts over 250  characters: 82134\n",
      "number of posts over 300 characters: 64611\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5033408\n",
      "Average length of body: 202.61892399741885\n",
      "number of posts over 50  characters: 3629278\n",
      "number of posts over 100  characters: 2579653\n",
      "number of posts over 150 characters: 1897668\n",
      "number of posts over 200  characters: 1456237\n",
      "number of posts over 250  characters: 1155323\n",
      "number of posts over 300 characters: 941578\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2428736\n",
      "Average length of body: 200.97222794078894\n",
      "number of posts over 50  characters: 1691007\n",
      "number of posts over 100  characters: 1215445\n",
      "number of posts over 150 characters: 901245\n",
      "number of posts over 200  characters: 693553\n",
      "number of posts over 250  characters: 548246\n",
      "number of posts over 300 characters: 444789\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434356\n",
      "Average length of body: 182.29371529344593\n",
      "number of posts over 50  characters: 319113\n",
      "number of posts over 100  characters: 222110\n",
      "number of posts over 150 characters: 156447\n",
      "number of posts over 200  characters: 113629\n",
      "number of posts over 250  characters: 85317\n",
      "number of posts over 300 characters: 65906\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184762\n",
      "Average length of body: 254.62208138037042\n",
      "number of posts over 50  characters: 148076\n",
      "number of posts over 100  characters: 116951\n",
      "number of posts over 150 characters: 91284\n",
      "number of posts over 200  characters: 72144\n",
      "number of posts over 250  characters: 57927\n",
      "number of posts over 300 characters: 47144\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843259\n",
      "Average length of body: 114.62820082560637\n",
      "number of posts over 50  characters: 501472\n",
      "number of posts over 100  characters: 285673\n",
      "number of posts over 150 characters: 179058\n",
      "number of posts over 200  characters: 120722\n",
      "number of posts over 250  characters: 86133\n",
      "number of posts over 300 characters: 63933\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to have atleast 50,000 posts from each subreddit, I will have to work with posts with lengths greater than 150 characters.  The subreddit with the least number of posts greater than 150 characters is \"Conservative\" with 69,784 posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an empty dataframe named temp_df and I populated it with the 11 elements of each post: parent_id, author, distinguished, body, gilded, score, author_flair_css_class, stickied, retreived_on, author_flair_text and id.  I probably won't use most of this meta data in my project, but I would rather preserve it incase I decide its useful later.  I then saved the dataframes as csv files to my local machine.  I will try to put the files on github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframes hold the data from the first 50,000 posts over length 150 characters in each subreddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Android.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Android.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Android.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/boardgames.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/boardgames.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/boardgames.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Conservative.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Conservative.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Conservative.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/hockey.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/hockey.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/hockey.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Libertarian.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Libertarian.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/Libertarian.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/neoliberal.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/neoliberal.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/neoliberal.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/politics.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/politics.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/politics.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n"
     ]
    }
   ],
   "source": [
    "x=0\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/worldnews.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/worldnews.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1\n",
    "with open(\"../../Reddit_Data_trimmed/June_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x <= 50000:\n",
    "            if len(line_in['body']) >=150:\n",
    "                with open('../../json_files/worldnews.txt', 'a') as outfile:\n",
    "                    outfile.write(line)\n",
    "                    if(x%1000==0):\n",
    "                         print(x)\n",
    "                    x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'parent_id':[], \n",
    "     'author':[], \n",
    "     'distinguished':[], \n",
    "     'body':[], \n",
    "     'gilded':[], \n",
    "     'score':[], \n",
    "     'author_flair_css_class':[],\n",
    "     'stickied':[],\n",
    "     'retrieved_on':[],\n",
    "     'author_flair_text':[],\n",
    "     'id':[]\n",
    "    }\n",
    "\n",
    "Android_df = pd.DataFrame(data=d)\n",
    "\n",
    "#Android_df = pd.read_json('../../json_files/Android.txt', orient='index')\n",
    "x=0\n",
    "with open('../../json_files/Android.txt', 'r') as infile:\n",
    "    for line in infile:\n",
    "        if(x<=49999):\n",
    "            line_in = json.loads(line)\n",
    "            Android_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "            Android_df.loc[x, 'author'] = line_in['author']\n",
    "            Android_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "            Android_df.loc[x, 'body'] = line_in['body']\n",
    "            Android_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "            Android_df.loc[x, 'score'] = line_in['score']\n",
    "            Android_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "            Android_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "            Android_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "            Android_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "            Android_df.loc[x, 'id'] = line_in['id']\n",
    "        x=x+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                      author author_flair_css_class  \\\n",
       "0         Worth_The_Squeeze                    NaN   \n",
       "1             startupreddit              userBlack   \n",
       "2                   Deksloc                    AMA   \n",
       "3         _ALLLLRIGHTY_THEN                   None   \n",
       "4                  the_scam                   None   \n",
       "5                   ragnore                   None   \n",
       "6            ProfessorWeeto                   None   \n",
       "7                  Satukoro              userBlack   \n",
       "8                 thechaosz                   None   \n",
       "9                   Imp0924               userGray   \n",
       "10           notveryenglish               userGray   \n",
       "11       van_goghs_pet_bear                   None   \n",
       "12                 the_scam                   None   \n",
       "13          innervisions710                   None   \n",
       "14           blue-sunrising                   None   \n",
       "15                  bliblio                   None   \n",
       "16                  dzrtguy                   None   \n",
       "17               rushingkar              userBlack   \n",
       "18               asdfman123                   None   \n",
       "19       van_goghs_pet_bear                   None   \n",
       "20            startupreddit              userBlack   \n",
       "21            formerfatboys                   None   \n",
       "22                  tb03102                   None   \n",
       "23               xSagittiSx                   None   \n",
       "24                    oZiix              userBlack   \n",
       "25                  Wesside                   None   \n",
       "26       imUGLYandimPROOUUD                   None   \n",
       "27         WesternAddiction                   None   \n",
       "28             Bobby-Botato                   None   \n",
       "29                    nlofe               userTeal   \n",
       "...                     ...                    ...   \n",
       "49970               V4ynard                   None   \n",
       "49971           regis_regis                   None   \n",
       "49972          agracadabara                   None   \n",
       "49973                 iskin                   None   \n",
       "49974                   jt4                userRed   \n",
       "49975                  BFCE               userGray   \n",
       "49976               Skripka               userBlue   \n",
       "49977   LifeLikeAndPoseable                   None   \n",
       "49978          benjimaestro                userRed   \n",
       "49979          agracadabara                   None   \n",
       "49980               Eridrus                   None   \n",
       "49981                bupku5                   None   \n",
       "49982  moto-throwaway-98252                   None   \n",
       "49983                  Rjwu                   None   \n",
       "49984              aecarol1                   None   \n",
       "49985           hellswaters              userBlack   \n",
       "49986       Didactic_Tomato              userBlack   \n",
       "49987               zeldar_                   None   \n",
       "49988               p4block                   None   \n",
       "49989              wilso850                   None   \n",
       "49990        anal_astronaut               userLime   \n",
       "49991   Crocoduck_The_Great                   None   \n",
       "49992               crescal              userBlack   \n",
       "49993                bupku5                   None   \n",
       "49994                mmapza               userBlue   \n",
       "49995              logoster               userGray   \n",
       "49996         avataraccount                   None   \n",
       "49997   LifeLikeAndPoseable                   None   \n",
       "49998       adithyathefreak                   None   \n",
       "49999                  jcpb               userTeal   \n",
       "\n",
       "                                       author_flair_text  \\\n",
       "0                                                    NaN   \n",
       "1                                                  Black   \n",
       "2                             /r/Android AMA Coordinator   \n",
       "3                                                   None   \n",
       "4                                                   None   \n",
       "5                                                   None   \n",
       "6                                                   None   \n",
       "7                                      Optimus Elite, GB   \n",
       "8                                                   None   \n",
       "9                                      Nexus 6P | 7.1.1    \n",
       "10                                           S4, S7 Edge   \n",
       "11                                                  None   \n",
       "12                                                  None   \n",
       "13                                                  None   \n",
       "14                                                  None   \n",
       "15                                                  None   \n",
       "16                                                  None   \n",
       "17                VZW Moto X (2014), 6.x CM | LG G Watch   \n",
       "18                                                  None   \n",
       "19                                                  None   \n",
       "20                                                 Black   \n",
       "21                                                  None   \n",
       "22                                                  None   \n",
       "23                                                  None   \n",
       "24                           Galaxy S7e/Nvidia Shield TV   \n",
       "25                                                  None   \n",
       "26                                                  None   \n",
       "27                                                  None   \n",
       "28                                                  None   \n",
       "29                                        T-Mobile LG G6   \n",
       "...                                                  ...   \n",
       "49970                                               None   \n",
       "49971                                               None   \n",
       "49972                                               None   \n",
       "49973                                               None   \n",
       "49974                           Pixel 2 is disappointing   \n",
       "49975  HTC M8 -&gt; LG V10 that bootloops (fuck lg) -...   \n",
       "49976                                      LG v20 Sprint   \n",
       "49977                                               None   \n",
       "49978              Redmi Note 3 Pro | Ressurection Remix   \n",
       "49979                                               None   \n",
       "49980                                               None   \n",
       "49981                                               None   \n",
       "49982                                               None   \n",
       "49983                                               None   \n",
       "49984                                               None   \n",
       "49985                                            Nexus 5   \n",
       "49986                                        Quite Black   \n",
       "49987                                               None   \n",
       "49988                                               None   \n",
       "49989                                               None   \n",
       "49990                  Nexus4-16; Nexus 5 Black/White 32   \n",
       "49991                                               None   \n",
       "49992                                              Black   \n",
       "49993                                               None   \n",
       "49994                                               Blue   \n",
       "49995                                    ATT Samsung GS7   \n",
       "49996                                               None   \n",
       "49997                                               None   \n",
       "49998                                               None   \n",
       "49999             iPhone 6S+ | iPhone X after 2017.10.27   \n",
       "\n",
       "                                                    body distinguished  \\\n",
       "0      I know. It's the thing I call the \"Apple spher...           NaN   \n",
       "1      I just really hope they keep the quality as it...           NaN   \n",
       "2      Sorry HollowmanNapkin, your submission has bee...     moderator   \n",
       "3      As someone who hasnt used a headphone jack in ...          None   \n",
       "4      I feel that they tend to submit patents for de...          None   \n",
       "5      1. For tablets, sure. For regular phones? Very...          None   \n",
       "6      I've never once ran out of juice using wireles...          None   \n",
       "7      The benchmark should be quality. LG has shown ...          None   \n",
       "8      Question. What is to gain from removing it? Ho...          None   \n",
       "9      Yeah but when there are only a few companies c...          None   \n",
       "10     I always carry a pen and tiny booklet in my po...          None   \n",
       "11     maybe for you, not for most people. wireless h...          None   \n",
       "12     This was November and then again in June. Same...          None   \n",
       "13     But what about Bluetooth headphone users? Many...          None   \n",
       "14     I really don't understand why people hate blue...          None   \n",
       "15     &gt;i disagree with that. same audio quality, ...          None   \n",
       "16     89% upvoted? It's insanity anyone would want t...          None   \n",
       "17     The main problem I have with the dongle is tha...          None   \n",
       "18     Maybe my thinking isn't laggardly, I just don'...          None   \n",
       "19     apple copies people all the time, obviously. b...          None   \n",
       "20     Oh boy, idk about anyone who would want to buy...          None   \n",
       "21     The biggest thing is that there are no headpho...          None   \n",
       "22     Man I love my LG tones. I'm on my 3rd pair. Us...          None   \n",
       "23     The 90% referred to having black bars while ga...          None   \n",
       "24     Agreed!  The same puff pieces pop on Apples re...          None   \n",
       "25     Except for the fact that it's still a screen t...          None   \n",
       "26     Anyone know anything about the \"better sound s...          None   \n",
       "27     Bluetooth headphones are great until they die....          None   \n",
       "28     HTC makes some of the best designed phones: Th...          None   \n",
       "29     I'll never understand why people would use FLA...          None   \n",
       "...                                                  ...           ...   \n",
       "49970  Looking for phones at the same price/performan...          None   \n",
       "49971  You can enable radio. The signal will be weake...          None   \n",
       "49972  &gt;Just search up \"iPhone + battery + worse\" ...          None   \n",
       "49973  I would need to see good proof of this claim. ...          None   \n",
       "49974  I've mentioned this before, but I have yet to ...          None   \n",
       "49975  * Speed\\n\\n* Charging\\n\\n* Battery life\\n\\n* S...          None   \n",
       "49976  Interestingly, in May 1911 the Harland and Wol...          None   \n",
       "49977  That's the mistake most consumers make: purcha...          None   \n",
       "49978  Wtf? Samsung are still copying apple after all...          None   \n",
       "49979  All that became irrelevant with Geekbench 4. L...          None   \n",
       "49980  Hmmm, can you link me to some instructions on ...          None   \n",
       "49981  and the Pixel C was another classic case of Go...          None   \n",
       "49982  Thanks for the input. I'm 99% sure I am going ...          None   \n",
       "49983  I have no idea what you're smoking, but iPhone...          None   \n",
       "49984  The 3DMark test is for the GPU, it’s not testi...          None   \n",
       "49985  As a Canadian in a province with the best cell...          None   \n",
       "49986  You should get your phone checked out. I just ...          None   \n",
       "49987  Cell service and data speeds can be very spott...          None   \n",
       "49988  Settings -&gt; Display -&gt; LiveDisplay \\n\\nI...          None   \n",
       "49989  I agree. As well as a clear all button for the...          None   \n",
       "49990  I pay 100 bucks for 2 lines and 50gb of data p...          None   \n",
       "49991  I know that list is complete as I sit here and...          None   \n",
       "49992  Samsung is probably doing better in US because...          None   \n",
       "49993  the Pixel2 will bellyflop hard but then Sundar...          None   \n",
       "49994  The best feature I miss from an old phone is F...          None   \n",
       "49995  Not me, I'll use fm over any streaming service...          None   \n",
       "49996  This article has design patent and renders. \\n...          None   \n",
       "49997  Because I don't want Google and third party de...          None   \n",
       "49998  I agree.\\n\\nWhat makes Android different from ...          None   \n",
       "49999  Skip the link, it's a fucking generic Wordpres...          None   \n",
       "\n",
       "       gilded       id   parent_id  retrieved_on  score stickied  \n",
       "0         0.0  dmehp79  t1_dme9izp  1.504557e+09    6.0    False  \n",
       "1         0.0  dmehp7m  t1_dmehj24  1.504557e+09    1.0    False  \n",
       "2         0.0  dmehpbd   t3_6xatxb  1.504557e+09    1.0    False  \n",
       "3         0.0  dmehpd3  t1_dme0181  1.504557e+09    2.0    False  \n",
       "4         0.0  dmehphy  t1_dmefgm7  1.504557e+09    1.0    False  \n",
       "5         0.0  dmehpye  t1_dmefsk0  1.504557e+09    3.0    False  \n",
       "6         0.0  dmehqjq  t1_dmehndm  1.504557e+09    0.0    False  \n",
       "7         0.0  dmehqvv  t1_dmehkqe  1.504557e+09    3.0    False  \n",
       "8         0.0  dmehrtr   t3_6x6o68  1.504557e+09    1.0    False  \n",
       "9         0.0  dmehtn0  t1_dmdj7va  1.504557e+09    1.0    False  \n",
       "10        0.0  dmehu2d   t3_6x676i  1.504557e+09    1.0    False  \n",
       "11        0.0  dmehvty  t1_dmeay68  1.504557e+09   -2.0    False  \n",
       "12        0.0  dmehwha  t1_dmegfzn  1.504557e+09    1.0    False  \n",
       "13        0.0  dmehwqv  t1_dmdozbz  1.504557e+09    1.0    False  \n",
       "14        0.0  dmehx3b  t1_dmeh0i3  1.504557e+09    4.0    False  \n",
       "15        0.0  dmehx7n  t1_dme8zyh  1.504557e+09    1.0    False  \n",
       "16        0.0  dmehx90   t3_6x6o68  1.504557e+09    2.0    False  \n",
       "17        0.0  dmehxyj  t1_dme8l01  1.504557e+09    1.0    False  \n",
       "18        0.0  dmehy1x  t1_dmegoa1  1.504557e+09    3.0    False  \n",
       "19        0.0  dmehy2p  t1_dme9vbg  1.504557e+09    0.0    False  \n",
       "20        0.0  dmehzka  t1_dmehtld  1.504557e+09   26.0    False  \n",
       "21        0.0  dmei18o   t3_6x6o68  1.504557e+09    2.0    False  \n",
       "22        0.0  dmei1ir  t1_dmdq3wa  1.504557e+09    1.0    False  \n",
       "23        0.0  dmei21e  t1_dmeg229  1.504557e+09    1.0    False  \n",
       "24        0.0  dmei2od  t1_dme5yxk  1.504557e+09    3.0    False  \n",
       "25        0.0  dmei3ln  t1_dmehsja  1.504557e+09   32.0    False  \n",
       "26        0.0  dmei5fz   t3_6x6o68  1.504557e+09    1.0    False  \n",
       "27        0.0  dmei5is  t1_dme8ykt  1.504557e+09    2.0    False  \n",
       "28        0.0  dmei5ok   t3_6x8phs  1.504557e+09    4.0    False  \n",
       "29        0.0  dmei5oz  t1_dme1i92  1.504557e+09   39.0    False  \n",
       "...       ...      ...         ...           ...    ...      ...  \n",
       "49970     0.0  dnfykmb   t3_71iegx  1.507057e+09    1.0    False  \n",
       "49971     0.0  dnfykym  t1_dnfh703  1.507057e+09    3.0    False  \n",
       "49972     0.0  dnfymon  t1_dnfwlob  1.507057e+09   11.0    False  \n",
       "49973     0.0  dnfynfa  t1_dnfs4vf  1.507057e+09    4.0    False  \n",
       "49974     0.0  dnfyqa4   t3_724h9a  1.507057e+09   10.0    False  \n",
       "49975     0.0  dnfyqi6   t3_723wow  1.507057e+09    3.0    False  \n",
       "49976     0.0  dnfyqlz   t3_725wdx  1.507057e+09    5.0    False  \n",
       "49977     0.0  dnfys3d  t1_dnfn2zn  1.507057e+09    0.0    False  \n",
       "49978     0.0  dnfytra   t3_725809  1.507057e+09   95.0    False  \n",
       "49979     0.0  dnfytxu  t1_dnfv064  1.507057e+09   19.0    False  \n",
       "49980     0.0  dnfyvrm  t1_dnfrx0k  1.507057e+09    1.0    False  \n",
       "49981     0.0  dnfyw62  t1_dnfnz9t  1.507057e+09    3.0    False  \n",
       "49982     0.0  dnfywwj  t1_dnftanz  1.507057e+09    2.0    False  \n",
       "49983     0.0  dnfyxkm  t1_dnfxysv  1.507057e+09   12.0    False  \n",
       "49984     0.0  dnfyyk4  t1_dnfy1ja  1.507057e+09   12.0    False  \n",
       "49985     0.0  dnfyzf0  t1_dnftt8l  1.507058e+09    1.0    False  \n",
       "49986     0.0  dnfyzk9  t1_dnek8v8  1.507058e+09    1.0    False  \n",
       "49987     0.0  dnfyzoq  t1_dnfpibg  1.507058e+09    1.0    False  \n",
       "49988     0.0  dnfz007  t1_dnfyvrm  1.507058e+09    1.0    False  \n",
       "49989     0.0  dnfz19r  t1_dnfyfqd  1.507058e+09    1.0    False  \n",
       "49990     0.0  dnfz1lb  t1_dnfeib5  1.507058e+09    1.0    False  \n",
       "49991     0.0  dnfz1w0   t3_71zd54  1.507058e+09    1.0    False  \n",
       "49992     0.0  dnfz4u8  t1_dnfq7hr  1.507058e+09    8.0    False  \n",
       "49993     0.0  dnfz520  t1_dnfsgo3  1.507058e+09    9.0    False  \n",
       "49994     0.0  dnfz59f   t3_722jiv  1.507058e+09   13.0    False  \n",
       "49995     0.0  dnfz5ip  t1_dnfrssm  1.507058e+09    1.0    False  \n",
       "49996     0.0  dnfz77v  t1_dnfxbp3  1.507058e+09   88.0    False  \n",
       "49997     0.0  dnfz8bn  t1_dnfmnr0  1.507058e+09    1.0    False  \n",
       "49998     0.0  dnfz8h6  t1_dnfyed5  1.507058e+09   31.0    False  \n",
       "49999     0.0  dnfz95b   t3_725wdx  1.507058e+09    2.0    False  \n",
       "\n",
       "[50000 rows x 11 columns]>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Android_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = {'parent_id':[], \n",
    "     'author':[], \n",
    "     'distinguished':[], \n",
    "     'body':[], \n",
    "     'gilded':[], \n",
    "     'score':[], \n",
    "     'author_flair_css_class':[],\n",
    "     'stickied':[],\n",
    "     'retrieved_on':[],\n",
    "     'author_flair_text':[],\n",
    "     'id':[]\n",
    "    }\n",
    "\n",
    "x = 0\n",
    "\n",
    "temp_df = pd.DataFrame(data=d)\n",
    "\n",
    "t = '../../csv_files'\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "temp_df.to_csv(t + '/Conservative.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/Libertarian.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "temp_df.to_csv(t + '/neoliberal.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/politics.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/worldnews.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/Android.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/boardgames.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/hockey.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

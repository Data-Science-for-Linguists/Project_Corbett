{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reddit Data Trimming\n",
    "Robert Corbett\n",
    "rwc27@pitt.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of the files, I can not provide the raw data files on github."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is the code I am using to extract data of interest from the very large corpus I am using for my projet.  In this example, I am using only one months worth of data and I will need to repeat this proccess for each month.  I am hoping to use atleast 1 year of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files I am using for this project are very large.  The file I'm using in this example is 48.1GB and contains all 84,658,503 posts to Reddit from August, 2017.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The files I am using for this project are very large.  The file I'm using in this esample is 48.1GB and contains all 84,658,503 posts to Reddit in August, 2017.  I started by creating a list of unique subreddits, of which there were 6,980, from the first 100,000 posts in the file.  I picked two dozen subreddits to extract from the file, one dozen are political and one dozen are not.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Filmmakers', 'Addons4Kodi', 'NotTimAndEric', 'Saber', 'The_Donald', 'JordanPeterson', 'AskReddit', 'Military', 'trashy', 'KitchenConfidential', 'TagPro', 'DotA2', 'PuzzleAndDragons', 'SecretWorldLegends', 'SquaredCircle', 'Tinder', 'buccos', 'brasil', 'niceguys', 'Norway', 'd3fecttesting', 'NYYankees', 'acrl', 'airsoft', 'loseit', 'women', 'RoastMe', 'business', 'runescape', 'harrypotter', 'solareclipse', 'SCP', 'techsupport', 'asoiaf', 'MDMA', 'RocketLeague', 'sex', 'Trivium', 'anime', 'politics', 'redsox', 'DebateReligion', 'pcmasterrace', 'Retconned', 'comicbookmovies', 'RocketLeagueExchange', 'Roadcam', 'CatGifs', 'Bondage', 'shittankiessay', 'starbound', 'halifax', 'ADHD', 'pathofexile', 'UpliftingNews', 'teenagers', 'nba', 'sg_playground', 'Games', 'leagueoflegends', 'KingdomHearts', 'BigBrother', 'MobiusFF', 'EnoughTrumpSpam', 'dvdcollection', 'AMA', 'indie_rock', 'HouseOfCards', 'Jokes', 'TheDickShow', 'Fishing', 'WaltDisneyWorld', 'Harmontown', 'ladybonersgw', 'kik', 'BlackPeopleTwitter', 'cscareerquestions', 'streetwear', 'Steam', 'bettafish', 'videos', 'milwaukee', 'pics', 'reddevils', 'Fantasy', 'GoneWildPlus', 'Awwducational', 'atheism', 'MensRights', 'titanfall', 'florida', 'GlobalOffensiveTrade', 'CringeAnarchy', 'iamverybadass', 'LateStageCapitalism', 'AskWomen', 'musicals', 'Teachers', 'AskTrumpSupporters', 'PoliticsWithoutTheBan', 'CrazyIdeas', 'JRPG', 'RepLadies', 'depression', 'battlefield_one', 'Neverwinter', 'nonmonogamy', 'thebachelor', 'incest', 'investing', 'exmormon', 'KotakuInAction', 'announcements', 'MLBTheShow', 'tipofmytongue', 'insurgency', 'hockey', 'vexillology', 'radiocontrol', 'formula1', 'fatlogic', 'Fitness', 'walmart', 'mildlyinteresting', 'darksouls3', 'bjj', 'Sat', 'typewriters', 'BitcoinMarkets', 'movies', 'JUSTNOMIL', 'gameofthrones', 'seinfeld', 'CompulsiveSkinPicking', 'Archaeology', 'INJUSTICE', 'StreamersGoneWild', 'nyjets', 'houston', 'ultimate', 'JurassicPark', 'news', 'AskNYC', 'PokemonGoMPLS', 'confession', 'science', 'ptcgo', 'NASCAR', 'diablo3', 'rpghorrorstories', 'HFY', 'WahoosTipi', 'benchmade', 'forhonor', 'audioengineering', 'gaming', 'Vive', 'nosleep', 'MMA', 'Defcon', 'worldpowers', 'AskAnAmerican', 'gifs', 'oddlysatisfying', 'KCRoyals', 'HaloStory', 'EarthFans', 'Brawlstars', 'footballmanagergames', 'thesopranos', 'nfl', 'asktrp', 'HomemadeGayPorn', 'newzealand', 'rule34', 'explainlikedrcox', 'RateMyNudeBody', 'funny', 'RyzeMains', 'personalfinance', 'Amd', 'UKPersonalFinance', 'rugbyunion', 'hearthstone', 'hiphopheads', 'PlantedTank', 'ketamine', 'DBZDokkanBattle', 'rant', 'watercooling', 'asatru', 'vegan', 'japancirclejerk', 'stlouisblues', 'fantasybaseball', 'penguins', 'splatoon', 'soccer', 'trees', 'hardwareswap', 'jaimebrienne', 'WTF', 'AskOuija', 'starcitizen', 'travel', 'Hoocoodanode', 'counting', 'heroesofthestorm', 'oculus', 'ChildrenFallingOver', 'Denver', 'gamegrumps', 'Libertarian', 'pnwriders', 'Futurism', 'marvelstudios', 'WeWantPlates', 'battlefield_live', 'fatpeoplestories', 'PUBATTLEGROUNDS', 'xboxone', 'AFL', 'guitarpedals', 'IronThronePowers', 'DestinyTheGame', 'GlobalOffensive', 'Philippines', 'Reformed', 'StudentLoans', 'Coffee', 'TTC_PCOS', 'OldSchoolCool', 'Charlotte', 'lawncare', 'ShitPoliticsSays', 'buildapcsales', 'CODZombies', 'rickandmorty', 'sports', 'TheSilphRoad', 'CoDCompPlays', 'hardware', 'changemyview', 'FierceFlow', 'conspiracy', 'exmuslim', 'TexasRangers', 'AskMen', 'PrequelMemes', 'magicTCG', 'Shadowrun', 'ShingekiNoKyojin', 'bladeandsoul', 'todayilearned', 'Aquariums', 'programming', 'explainlikeimfive', 'CHIBears', 'BlackMetal', 'wallstreetbets', 'NoStupidQuestions', 'weddingplanning', 'dating_advice', 'Austin', 'Indiana', 'funkopop', 'RedditSilverRobot', 'Pyongyang', 'smashbros', 'Warthunder', 'ActionFigures', 'rupaulsdragrace', 'PoliticalDiscussion', 'vancouver', '3DS', 'askscience', 'PoliticalHumor', 'CalPoly', 'eatsandwiches', 'LosAngeles', 'EatCheapAndHealthy', 'germany', 'korea', 'AskRedditAfterDark', 'BrantSteele', 'learnmath', 'CrusaderKings', 'ems', 'ESFJ', 'holdmyfries', 'bestof', 'pokemongo', 'guns', 'KyliePage', 'Roast_Me', 'buildapc', 'noveltranslations', 'donaldglover', 'television', 'firefox', 'discgolf', 'EDC', 'woahdude', 'wholesomememes', 'pokemonduel', 'freefolk', 'blender', 'pcgamingtechsupport', 'vzla', 'MachineLearning', 'SubredditSimulator', 'NatureIsFuckingLit', 'Unexpected', 'pokemon', 'INTP', 'howardstern', 'ireland', 'diypedals', 'Drama', 'medical', 'edc_raffle', 'pureasoiaf', 'MtF', 'MakeupAddiction', 'bostonceltics', 'Conservative', 'indieheads', 'yiff', 'CasualConversation', 'DrugStashes', 'TownofSalemgame', 'thatHappened', 'DunderMifflin', 'army', 'casualiama', 'LigaMX', '4chan', 'Warframe', 'Pareidolia', 'evenewbies', 'PSVR', 'FinalFantasy', 'IASIP', 'teslamotors', 'WorldOfWarships', 'SUBREDDITNAME', 'gmod', 'Overwatch', 'ComedyCemetery', 'CEOfriendly', 'ImagesOfromania', 'Realestatefinance', 'Rainmeter', 'toofers', 'mopeio', 'SanctionedSuicide', 'GuitarHero', 'LifeProTips', 'DataHoarder', 'grandrapids', 'Delightfullychubby', 'college', 'Sneakers', 'NewsOfTheStupid', 'wow', 'Morrowind', 'PublicFreakout', 'leafs', 'chile', 'buildapcforme', 'WayOfTheBern', 'nottheonion', 'canada', 'comicbooks', 'legaladvice', 'fashionsouls', 'anime_irl', 'Warhammer40k', 'drummers', 'NoSillySuffix', 'nevertellmetheodds', 'NBA2k', 'ThePeoplesRCigars', 'polandball', 'breakingmom', 'amateurradio', 'RotMG', 'justneckbeardthings', 'unpopularopinion', 'traps', 'fantasybball', 'youngjustice', 'ETHInsider', 'childfree', 'worstepisodeever', 'BullTerrier', 'LastDayonEarthGame', 'ffxiv', 'MemeEconomy', 'HatsuVault', 'askgaybros', 'GCdebatesQT', 'JoeRogan', 'keto', 'howto', 'FFBraveExvius', 'AnimalsBeingBros', 'malefashionadvice', 'OnePiece', 'eldertrees', 'microgrowery', 'MechanicalKeyboards', 'AmateurRoomPorn', 'MorganHultgren', 'Morristown', 'caseyneistat', 'OutOfTheLoop', 'pcgaming', 'AgainstHateSubreddits', 'beer', 'GamerPals', 'stopsmoking', 'ddlg', 'CFB', 'Competitiveoverwatch', 'totalwar', 'iOSProgramming', 'ripcity', 'SeattleWA', 'raisedbynarcissists', 'lonely', 'lewronggeneration', 'Madden', 'IncelTears', 'OkCupid', 'CampHalfBloodRP', 'worldnews', 'LowTierTradingRL', 'Atlanta', 'motorcycles', 'NewSkaters', 'simpleliving', 'quittingkratom', 'FireEmblemHeroes', 'bdsm', 'singedmains', 'Dariusmains', 'metaldetecting', 'Malazan', 'Dota2Trade', 'Eve', 'RateMyMayor', 'opieandanthony', 'TrumpCriticizesTrump', 'Marvel', 'Justrolledintotheshop', 'ABraThatFits', 'arrow', 'SanJose', 'halloween', '40kLore', 'lifeisstrange', 'melbourne', 'economy', 'singapore', 'FFRecordKeeper', 'DIY_eJuice', 'survivor', 'OnePieceTC', 'cowboys', 'IMDbFilmGeneral', 'DNMUK', 'Torontobluejays', 'MkeBucks', 'BeautyBoxes', 'nakedladies', 'KingkillerChronicle', 'Advice', 'photography', 'Bitcoin', 'RandomActsOfGaming', 'gonewild', 'Tekken', 'electronic_cigarette', 'CrappyDesign', 'writing', 'DirtySnapchat', 'mallninjashit', 'MrRobot', 'intj', 'leaves', 'F13thegame', 'Career_Advice', 'AnimalsBeingJerks', 'france', 'Cigarettes', 'gamindustri', 'suggestmeabook', 'FloridaGators', 'aww', 'Flute', 'Showerthoughts', 'TrollXChromosomes', 'worldbuilding', 'Goruck', 'fakeid', 'linux', 'Brewers', 'PoGoDFW', 'SubredditDrama', 'eu4', 'ChoosingBeggars', 'iamverysmart', 'badwomensanatomy', 'flatearth', 'Rainbow6', 'nrl', 'dankmemes', 'indianpeoplefacebook', 'sydney', 'Christianity', 'fordranger', 'Guildwars2', 'BitcoinAll', 'FemBoys', 'russian', 'ThriftStoreHauls', 'short', 'relationship_advice', 'Infinitewarfare', 'speedrun', 'UMD', 'pocketrumble', 'Nioh', 'gtaonline', 'JapanTravel', 'usanews', 'dirtypenpals', 'Berserk', 'Indiemakeupandmore', 'blackpeoplegifs', 'HardwareSwapUK', 'ak47', 'shakespeare', 'stopdrinking', 'MMORPG', 'quotes', 'gonewild30plus', 'uber', 'Frat', 'twinpeaks', 'Kaiserreich', 'DecemberBumpers2017', 'FIFA', 'Staples', 'swgoh_guilds', 'me_irl', 'SubaruForester', 'interestingasfuck', 'CitiesSkylines', '2007scape', 'canucks', 'supremeclothing', 'future_fight', 'CHICubs', 'thedivision', 'FoundPaper', 'grandorder', 'cringe', 'Catholicism', 'poker', 'australia', 'WredditCountryClub', 'exjw', 'doctorwho', 'NoMansSkyTheGame', 'asstastic', 'tattoos', 'baseball', 'sadcringe', 'whitesox', 'gaybros', 'youtubecomments', 'lawschooladmissions', 'WritingPrompts', 'asktransgender', 'DynastyFF', 'uwaterloo', 'sousvide', 'geopolitics', 'nyc', 'Drugs', 'slaterefugees', 'JizzedToThis', 'milliondollarextreme', 'Bobbers', 'MouseReview', 'redditgetsdrawn', 'ImagesOfCanada', 'NHLHUT', 'FinalFantasyTCG', 'ProgrammerHumor', 'blackops3', 'DuelLinks', 'NMSGalacticHub', 'Android', 'TryingForABaby', 'opiates', 'tucker_carlson', 'flightsim', 'RWBY', 'elderscrollsonline', 'StarWarsBattlefront', 'Texans', 'boston', 'Serendipity', 'makeupexchange', 'RealGirls', 'NoFapChristians', 'shittyrainbow6', 'Futurology', 'Trove', 'dirtykikpals', 'argentina', 'Random_Acts_Of_Amazon', 'NintendoSwitch', 'EngineeringStudents', 'keming', 'askfuneraldirectors', 'NoFap', 'fo4', 'androidapps', 'ethereum', 'gonewildcurvy', 'CapitalismVSocialism', 'orioles', 'arcadefire', 'nextdaysurvival', 'ContestOfChampions', 'bigdickproblems', 'GooglePixel', 'GamerGhazi', 'electronics', 'MakeupRehab', 'Ubiq', 'EliteDangerous', 'Syracuse', 'Ohio', 'fantasyfootball', 'Parkour', 'TrueFMK', 'Mordhau', 'blackdesertonline', 'HealthInsurance', 'ExpandDong', 'theydidthemath', 'boardgames', 'foxholegame', 'longrange', 'H3VR', 'btc', 'wowservers', 'portugal', 'sandiego', 'Shadowverse', 'ImagesOfAustralia', 'photoshopbattles', 'namenerds', 'DC_Cinematic', 'dogs', 'thesims', 'skeptic', 'kratom', 'furry_irl', 'kpop', 'playrust', 'GTAV', 'synthesizers', 'CallOfDuty', 'NeverTrump', 'playark', 'whatisthisthing', 'TumblrInAction', 'Glocks', 'forwardsfromgrandma', 'canadaguns', 'GameSale', 'UnresolvedMysteries', 'ExploreFiction', '2meirl4meirl', 'FashionReps', 'relationships', 'fountainpens', 'Quebec', 'GetMotivated', 'facebookwins', 'treephilly', 'EscapefromTarkov', 'BannedFromThe_Donald', 'DebateCommunism', 'SweatyPalms', 'Repsneakers', 'watchpeopledie', 'Steroidsourcetalk', 'DCComicsLegendsGame', 'maryland', 'ElectricSkateboarding', 'psg', 'shortscarystories', 'FocusST', 'ShitWehraboosSay', 'mexico', 'ABDL', 'starterpacks', 'AnnePro', 'patientgamers', 'C_S_T', 'forza', 'horror', 'popping', 'fivenightsatfreddys', 'spotted', 'Cumtown', 'redacted', 'JonTron', 'shylittlesunflower', 'battlefield_4', 'offmychest', 'pipemaking', 'nursing', 'OfficeDepot', 'Ripple', 'flying', 'ForeverAlone', 'rollercoasters', 'Anticonsumption', 'polyamory', 'sanfrancisco', 'LifeRPG', 'Guiltygear', 'cars', 'orangetheory', 'sales', 'drupal', 'DebateAChristian', 'summonerschool', 'rust', 'TapTitans2', 'ApplyingToCollege', 'PS4Deals', 'tf2', 'MST3K', 'Woodcarving', 'dndnext', 'europe', 'socialskills', 'Unity3D', 'Miata', 'transpositive', 'AskThe_Donald', 'kindafunny', 'TheRedPill', 'reactiongifs', 'WeAreTheMusicMakers', 'TokyoGhoul', 'Grimdank', 'Smite', 'nasusmains', 'Ducati', 'DeFranco', 'starshiptroopers', 'mildlyinfuriating', 'CryptoCurrency', 'Denmark', 'rotmgprojectb', 'seduction', 'AmateurWifes', 'skyrim', 'AmericanHorrorStory', 'photomarket', 'nintendo', 'homelabsales', 'shockwaveporn', 'avengersacademygame', 'motorcitykitties', 'YGOSales', 'secretsubgonewild', 'Mcat', 'BurningMan', 'thewallstreet', 'neoliberal', 'gwent', 'TwoBestFriendsPlay', 'FellowKids', 'EmmaWatson', 'battlebots', 'philadelphia', 'madlads', 'headphones', 'OnceUponAnEnd', 'redheads', 'RetributionOfScyrah', 'photoshop', 'TenYearsAgoOnReddit', 'BBQ', 'Winnipeg', 'mixedrace', 'wholesomebpt', 'ACT', 'YouEnterADungeon', 'CSRRacing2', 'Watches', 'StarWars', 'replications', 'FUTMobile', 'AskEurope', 'StarTrekContinues', 'LabourUK', 'roadtrip', 'pharmacy', 'CasualUK', 'ledgerwallet', 'MovieDetails', 'cocktails', 'Bass', 'HaircareScience', 'PC_Builders', 'AssholeBehindThong', 'FiveYearsAgoOnReddit', 'transformers', 'infertility', 'williamandmary', 'HondaCB', 'AccidentalWesAnderson', 'ethtrader', 'amiugly', 'verizon', 'paragon', 'Stellaris', 'Ice_Poseidon', 'retrogaming', 'watch_dogs', 'japan', 'panthers', 'TIL_Uncensored', 'Monero', 'Mario', 'math', 'CFA', 'canadagunsEE', 'SFGiants', 'AsiansGoneWild', 'newsokur', 'CLG', 'EntExchange', 'XWingTMG', 'RedPillWomen', 'Megaten', 'iOSthemes', 'churning', 'mechmarket', 'skateboarding', 'chicago', 'retrobattlestations', 'HuntsvilleAlabama', 'chibike', 'rpg', 'origin', 'Cyberpunk', 'puppy101', 'answers', 'SchoolIdolFestival', 'CalamariRaceTeam', 'fullmoviesonanything', 'evangelion', 'Mariners', 'ClashOfClans', 'bicycling', 'AbletonProductions', 'starcraft', 'HumansBeingBros', 'nSuns', 'cigars', 'Vault_Tec_Corporation', 'GalaxyS8', 'progmetal', 'IAmA', 'HeistTeams', 'cookingforbeginners', 'Hulu', 'LetItDie', 'skrillex', 'borussiadortmund', 'Portland', 'brisbane', 'Patriots', 'memes', 'gunpolitics', 'AntiJokes', 'Jeopardy', 'MarchAgainstTrump', 'esist', 'ANI_COMMUNISM', 'YGOBinders', 'Dodgers', 'Miniswap', 'ImagesOfArgentina', 'walkingwarrobots', 'TheOriginals', 'SketchDaily', 'Helldivers', 'ukpolitics', 'GameDeals', 'greece', 'MakeupAddictionCanada', 'MasterofNone', 'Enough_Sanders_Spam', '3Dprinting', 'DCcomics', 'food', 'kancolle', 'espnyankees', 'CCW', 'longisland', '1200isplenty', 'apple', 'rawdenim', 'kickstarter', 'TOtrees', 'LipsThatGrip', 'Intelligence', 'AndroidMasterRace', 'Injustice2MobileGame', 'Tiki', 'Mustang', 'CrohnsDisease', '3dspiracy', 'masseffect', 'trashyboners', 'AdviceAnimals', 'giantbomb', 'MTGLegacy', 'hockeyplayers', 'G502MasterRace', 'Guitar', 'GoneMild']\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "Subreddit = []\n",
    "with open(\"sample_data.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if line_in['subreddit'] not in Subreddit:\n",
    "            #print(line_in['subreddit'])\n",
    "            Subreddit.append(line_in['subreddit'])\n",
    "        x = x + 1\n",
    "        if x == 100000:\n",
    "            break\n",
    "print(Subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "946\n"
     ]
    }
   ],
   "source": [
    "print(len(Subreddit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created an empty list for each subreddit I am extracting.  I then open the file and loop through each json entry one at a time examining the 'subreddit' field and appending the line to the appropriate list when it is found.  If the 'subreddit' field does not match any of the strings I'm searching for, I add 1 to the variable other so I can later check that every entry was checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "The_Donald = []\n",
    "politics = []\n",
    "indie_rock = []\n",
    "AskTrumpSupporters = []\n",
    "PoliticsWithoutTheBan = []\n",
    "hockey = []\n",
    "seinfeld = []\n",
    "Archaeology = []\n",
    "Libertarian = []\n",
    "Futurism = []\n",
    "Conservative = []\n",
    "indieheads = []\n",
    "worldnews = []\n",
    "photography = []\n",
    "geopolitics = []\n",
    "Android = []\n",
    "boardgames = []\n",
    "NeverTrump = []\n",
    "neoliberal = []\n",
    "headphones = []\n",
    "gunpolitics = []\n",
    "MarchAgainstTrump = []\n",
    "DCcomics = []\n",
    "food = []\n",
    "other = 0\n",
    "with open(\"sample_data.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        subreddit = line_in['subreddit']\n",
    "        if subreddit == 'The_Donald':\n",
    "            The_Donald.append(line_in)\n",
    "        elif subreddit == 'politics':\n",
    "            politics.append(line_in)\n",
    "        elif subreddit == 'indie_rock':\n",
    "            indie_rock.append(line_in)\n",
    "        elif subreddit == 'AskTrumpSupporters':\n",
    "            AskTrumpSupporters.append(line_in)\n",
    "        elif subreddit == 'PoliticsWithoutTheBan':\n",
    "            PoliticsWithoutTheBan.append(line_in)\n",
    "        elif subreddit == 'hockey':\n",
    "            hockey.append(line_in)\n",
    "        elif subreddit == 'seinfeld':\n",
    "            seinfeld.append(line_in)\n",
    "        elif subreddit == 'Archaeology':\n",
    "            Archaeology.append(line_in)\n",
    "        elif subreddit == 'Libertarian':\n",
    "            Libertarian.append(line_in)\n",
    "        elif subreddit == 'Futurism':\n",
    "            Futurism.append(line_in)\n",
    "        elif subreddit == 'Conservative':\n",
    "            Conservative.append(line_in)\n",
    "        elif subreddit == 'indieheads':\n",
    "            indieheads.append(line_in)\n",
    "        elif subreddit == 'worldnews':\n",
    "            worldnews.append(line_in)\n",
    "        elif subreddit == 'photography':\n",
    "            photography.append(line_in)\n",
    "        elif subreddit == 'geopolitics':\n",
    "            geopolitics.append(line_in)\n",
    "        elif subreddit == 'Android':\n",
    "            Android.append(line_in)\n",
    "        elif subreddit == 'boardgames':\n",
    "            boardgames.append(line_in)\n",
    "        elif subreddit == 'NeverTrump':\n",
    "            NeverTrump.append(line_in)\n",
    "        elif subreddit == 'neoliberal':\n",
    "            neoliberal.append(line_in)\n",
    "        elif subreddit == 'headphones':\n",
    "            headphones.append(line_in)\n",
    "        elif subreddit == 'gunpolitics':\n",
    "            gunpolitics.append(line_in)\n",
    "        elif subreddit == 'MarchAgainstTrump':\n",
    "            MarchAgainstTrump.append(line_in)\n",
    "        elif subreddit == 'DCcomics':\n",
    "            DCcomics.append(line_in)\n",
    "        elif subreddit == 'food':\n",
    "            food.append(line_in)\n",
    "        else:\n",
    "            other = other +1\n",
    "        x = x + 1\n",
    "        #if x == 100000:   allows me to iterate through a portion of the file instead of the whole file\n",
    "        #    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I checked how many posts I retrieved from each subreddit.  The variable x tracks how many posts I extracted so I can add it to the 'other' variable so I can make sure all posts where checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The_Donald: 22\n",
      "politics: 67\n",
      "indie_rock: 1\n",
      "AskTrumpSupporters: 4\n",
      "PolitisWithoutTheBan: 1\n",
      "hockey: 4\n",
      "seinfeld: 1\n",
      "Archaeology: 1\n",
      "Libertarian: 4\n",
      "Futurism: 1\n",
      "Conservative: 2\n",
      "indie_heads: 1\n",
      "worldnews: 15\n",
      "photography: 2\n",
      "geopolitics: 1\n",
      "Android: 4\n",
      "boardgames: 4\n",
      "NeverTrump: 1\n",
      "neoliberal: 1\n",
      "headphones: 1\n",
      "gunpolitics: 1\n",
      "MarchAgainstTrump: 1\n",
      "DCcomics: 1\n",
      "food: 1\n",
      "total: 142\n",
      "check sum: 2000\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "print('The_Donald: ' + str(len(The_Donald)))\n",
    "x = x + len(The_Donald)\n",
    "\n",
    "print('politics: ' + str(len(politics)))\n",
    "x = x + len(politics)\n",
    "\n",
    "print('indie_rock: ' + str(len(indie_rock)))\n",
    "x = x + len(indie_rock)\n",
    "\n",
    "print('AskTrumpSupporters: ' + str(len(AskTrumpSupporters)))\n",
    "x = x + len(AskTrumpSupporters)\n",
    "\n",
    "print('PolitisWithoutTheBan: ' + str(len(PoliticsWithoutTheBan)))\n",
    "x = x + len(PoliticsWithoutTheBan)\n",
    "\n",
    "print('hockey: ' + str(len(hockey)))\n",
    "x = x + len(hockey)\n",
    "\n",
    "print('seinfeld: ' + str(len(seinfeld)))\n",
    "x = x + len(seinfeld)\n",
    "\n",
    "print('Archaeology: ' + str(len(Archaeology)))\n",
    "x = x + len(Archaeology)\n",
    "\n",
    "print('Libertarian: ' + str(len(Libertarian)))\n",
    "x = x + len(Libertarian)\n",
    "\n",
    "print('Futurism: ' + str(len(Futurism)))\n",
    "x = x + len(Futurism)\n",
    "\n",
    "print('Conservative: ' + str(len(Conservative)))\n",
    "x = x + len(Conservative)\n",
    "\n",
    "print('indie_heads: ' + str(len(indieheads)))\n",
    "x = x + len(indieheads)\n",
    "\n",
    "print('worldnews: ' + str(len(worldnews)))\n",
    "x = x + len(worldnews)\n",
    "\n",
    "print('photography: ' + str(len(photography)))\n",
    "x = x + len(photography)\n",
    "\n",
    "print('geopolitics: ' + str(len(geopolitics)))\n",
    "x = x +len(geopolitics)\n",
    "\n",
    "print('Android: ' + str(len(Android)))\n",
    "x = x + len(Android)\n",
    "\n",
    "print('boardgames: ' + str(len(boardgames)))\n",
    "x = x + len(boardgames)\n",
    "\n",
    "print('NeverTrump: ' + str(len(NeverTrump)))\n",
    "x = x + len(NeverTrump)\n",
    "\n",
    "print('neoliberal: ' + str(len(neoliberal)))\n",
    "x = x + len(neoliberal)\n",
    "\n",
    "print('headphones: ' + str(len(headphones)))\n",
    "x = x + len(headphones)\n",
    "\n",
    "print('gunpolitics: ' + str(len(gunpolitics)))\n",
    "x = x + len(gunpolitics)\n",
    "\n",
    "print('MarchAgainstTrump: ' + str(len(MarchAgainstTrump)))\n",
    "x = x + len(MarchAgainstTrump)\n",
    "\n",
    "print('DCcomics: ' + str(len(DCcomics)))\n",
    "x = x + len(DCcomics)\n",
    "\n",
    "print('food: ' + str(len(food)))\n",
    "x = x + len(food)\n",
    "\n",
    "print('total: ' + str(x))\n",
    "print('check sum: ' + str(x + other))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then saved the lists as .txt files and preserved their json formats so I can use them later.  I saved them to a file named August_17 and the entire file is only 2.83GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'August_17'\n",
    "\n",
    "with open(s + '/The_Donald.txt', 'w') as outfile:\n",
    "    for item in The_Donald:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/politics.txt', 'w') as outfile:\n",
    "    for item in politics:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/indie_rock.txt', 'w') as outfile:\n",
    "    for item in indie_rock:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/AskTrumpSupporters.txt', 'w') as outfile:\n",
    "    for item in AskTrumpSupporters:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/PoliticsWithoutTheBan.txt', 'w') as outfile:\n",
    "    for item in PoliticsWithoutTheBan:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "\n",
    "with open(s + '/hockey.txt', 'w') as outfile:\n",
    "    for item in hockey:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/seinfeld.txt', 'w') as outfile:\n",
    "    for item in seinfeld:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/Archaeology.txt', 'w') as outfile:\n",
    "    for item in Archaeology:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/Libertarian.txt', 'w') as outfile:\n",
    "    for item in Libertarian:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/Futurism.txt', 'w') as outfile:\n",
    "    for item in Futurism:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/Conservative.txt', 'w') as outfile:\n",
    "    for item in Conservative:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/indieheads.txt', 'w') as outfile:\n",
    "    for item in indieheads:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/worldnews.txt', 'w') as outfile:\n",
    "    for item in worldnews:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/photography.txt', 'w') as outfile:\n",
    "    for item in photography:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/geopolitics.txt', 'w') as outfile:\n",
    "    for item in geopolitics:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/Android.txt', 'w') as outfile:\n",
    "    for item in Android:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/boardgames.txt', 'w') as outfile:\n",
    "    for item in boardgames:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/NeverTrump.txt', 'w') as outfile:\n",
    "    for item in NeverTrump:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/neoliberal.txt', 'w') as outfile:\n",
    "    for item in neoliberal:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/headphones.txt', 'w') as outfile:\n",
    "    for item in headphones:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/gunpolitics.txt', 'w') as outfile:\n",
    "    for item in gunpolitics:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/MarchAgainstTrump.txt', 'w') as outfile:\n",
    "    for item in MarchAgainstTrump:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "    \n",
    "with open(s + '/DCcomics.txt', 'w') as outfile:\n",
    "    for item in DCcomics:\n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")\n",
    "        \n",
    "with open(s + '/food.txt', 'w') as outfile:\n",
    "    for item in food:    \n",
    "        json.dump(item, outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program took several hours to run. I wanted to use timeit but when I looked into it, I found that timeit turns off automatic garbage collection and I was afraid with such a large file, that it might cause problems with memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x = 0\n",
    "#list_range = range(len(lines))\n",
    "#for i in list_range:\n",
    "#    foo = (lines[i - 1])\n",
    "#    beg = 0\n",
    "#    while beg != -1:\n",
    "#        beg = foo.find('apple', beg + 1)\n",
    "#        if beg != -1:\n",
    "#            print(\"line: \" + str(i) + \"    \" + foo + \" \\n\")\n",
    "#            x = x + 1\n",
    "#print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robert Corbett\n",
    "\n",
    "Reddit post exploration part 2\n",
    "\n",
    "This code is used to just find the number of posts I extracted from each subreddit. I have a large amount of data to choose from so I am only going to use a couple months of posts. The number of posts each subreddit has varies drastically. Some subreddits have hundreds of thousands of posts while some of a couple hundred. For the project, I want to use subreddits that have atleast 50,000 posts to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import nltk\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started by counting the number of lines in the json file for September, 2017.  I saved the total in a variable with the same name and printed the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of September, 2017\n",
      "Len of Android: 165509\n",
      "Len of Archaeology: 574\n",
      "Len of AskTrumpSupporters: 41290\n",
      "Len of boardgames: 61240\n",
      "Len of Conservative: 55766\n",
      "Len of DCcomics: 24647\n",
      "Len of food: 69709\n",
      "Len of Futurism: 197\n",
      "Len of geopolitics: 7313\n",
      "Len of gunpolitics: 4390\n",
      "Len of headphones: 29723\n",
      "Len of hockey: 199269\n",
      "Len of indie_rock: 491\n",
      "Len of indieheads: 35572\n",
      "Len of Libertarian: 103633\n",
      "Len of MarchAgainstTrump: 11761\n",
      "Len of neoliberal: 212190\n",
      "Len of NeverTrump: 180\n",
      "Len of photography: 36431\n",
      "Len of politics: 1390463\n",
      "Len of PoliticsWithoutTheBan: 0\n",
      "Len of seinfeld: 5277\n",
      "Len of The_Donald: 904159\n",
      "Len of worldnews: 777276\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/September_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of September, 2017\")\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did the same for August, 2017 but added the totals to the totals for September and printed the totals for the month below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of August, 2017\n",
      "Len of Android: 143884\n",
      "Len of Archaeology: 805\n",
      "Len of AskTrumpSupporters: 45575\n",
      "Len of boardgames: 60254\n",
      "Len of Conservative: 66364\n",
      "Len of DCcomics: 27988\n",
      "Len of food: 68758\n",
      "Len of Futurism: 187\n",
      "Len of geopolitics: 6269\n",
      "Len of gunpolitics: 2836\n",
      "Len of headphones: 30372\n",
      "Len of hockey: 157833\n",
      "Len of indie_rock: 320\n",
      "Len of indieheads: 39867\n",
      "Len of Libertarian: 94092\n",
      "Len of MarchAgainstTrump: 19208\n",
      "Len of neoliberal: 184248\n",
      "Len of NeverTrump: 322\n",
      "Len of photography: 41420\n",
      "Len of politics: 1824215\n",
      "Len of PoliticsWithoutTheBan: 10\n",
      "Len of seinfeld: 4045\n",
      "Len of The_Donald: 1057483\n",
      "Len of worldnews: 741492\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/August_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of August, 2017\")\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = Android + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = Archaeology + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = AskTrumpSupporters + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = boardgames + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = Conservative + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = DCcomics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = food + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = Futurism + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = geopolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = gunpolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = headphones + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = hockey + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = indie_rock + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = indieheads + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = Libertarian + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = MarchAgainstTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = neoliberal + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = NeverTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = photography + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = politics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = PoliticsWithoutTheBan + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = seinfeld + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = The_Donald + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = worldnews + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data for July was corrupted and I could not get the json entries to open.  So I skipped July and am going to use June instead.  I do not see skipping July causing any problems with the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for the month of June, 2017\n",
      "Len of Android: 124963\n",
      "Len of Archaeology: 524\n",
      "Len of AskTrumpSupporters: 44644\n",
      "Len of boardgames: 63268\n",
      "Len of Conservative: 47492\n",
      "Len of DCcomics: 33775\n",
      "Len of food: 67223\n",
      "Len of Futurism: 161\n",
      "Len of geopolitics: 6086\n",
      "Len of gunpolitics: 3777\n",
      "Len of headphones: 26346\n",
      "Len of hockey: 486157\n",
      "Len of indie_rock: 250\n",
      "Len of indieheads: 39393\n",
      "Len of Libertarian: 83183\n",
      "Len of MarchAgainstTrump: 67415\n",
      "Len of neoliberal: 160842\n",
      "Len of NeverTrump: 327\n",
      "Len of photography: 40423\n",
      "Len of politics: 1818730\n",
      "Len of PoliticsWithoutTheBan: 0\n",
      "Len of seinfeld: 3882\n",
      "Len of The_Donald: 1158567\n",
      "Len of worldnews: 909968\n"
     ]
    }
   ],
   "source": [
    "path = \"../../Reddit_Data_Trimmed/June_17/\"\n",
    "\n",
    "print(\"The number of posts in each subreddit for the month of June, 2017\")\n",
    "x = 0\n",
    "with open(path + \"Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Android: \" + str(x))\n",
    "Android = Android + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Archaeology.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Archaeology: \" + str(x))\n",
    "Archaeology = Archaeology + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"AskTrumpSupporters.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of AskTrumpSupporters: \" + str(x))\n",
    "AskTrumpSupporters = AskTrumpSupporters + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of boardgames: \" + str(x))\n",
    "boardgames = boardgames + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Conservative: \" + str(x))\n",
    "Conservative = Conservative + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"DCcomics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of DCcomics: \" + str(x))\n",
    "DCcomics = DCcomics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"food.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of food: \" + str(x))\n",
    "food = food + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Futurism.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Futurism: \" + str(x))\n",
    "Futurism = Futurism + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"geopolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of geopolitics: \" + str(x))\n",
    "geopolitics = geopolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"gunpolitics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of gunpolitics: \" + str(x))\n",
    "gunpolitics = gunpolitics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"headphones.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of headphones: \" + str(x))\n",
    "headphones = headphones + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of hockey: \" + str(x))\n",
    "hockey = hockey + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indie_rock.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indie_rock: \" + str(x))\n",
    "indie_rock = indie_rock + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"indieheads.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of indieheads: \" + str(x))\n",
    "indieheads = indieheads + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of Libertarian: \" + str(x))\n",
    "Libertarian = Libertarian + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"MarchAgainstTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of MarchAgainstTrump: \" + str(x))\n",
    "MarchAgainstTrump = MarchAgainstTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of neoliberal: \" + str(x))\n",
    "neoliberal = neoliberal + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"NeverTrump.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of NeverTrump: \" + str(x))\n",
    "NeverTrump = NeverTrump + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"photography.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of photography: \" + str(x))\n",
    "photography = photography + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of politics: \" + str(x))\n",
    "politics = politics + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"PoliticsWithoutTheBan.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of PoliticsWithoutTheBan: \" + str(x))\n",
    "PoliticsWithoutTheBan = PoliticsWithoutTheBan + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"seinfeld.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of seinfeld: \" + str(x))\n",
    "seinfeld = seinfeld + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"The_Donald.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of The_Donald: \" + str(x))\n",
    "The_Donald = The_Donald + x\n",
    "\n",
    "x = 0\n",
    "with open(path + \"worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        x = x + 1\n",
    "print(\"Len of worldnews: \" + str(x))\n",
    "worldnews = worldnews + x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, below I printed the totals for each subreddit for the three months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of posts in each subreddit for both months\n",
      "Android: 434356\n",
      "Archaeology: 1903\n",
      "AskTrumpSupporters: 131509\n",
      "boardgames: 184762\n",
      "Conservative: 169622\n",
      "DCcomics: 86410\n",
      "food: 205690\n",
      "Futurism: 545\n",
      "geopolitics: 19668\n",
      "gunpolitics: 11003\n",
      "headphones: 86441\n",
      "hockey: 843259\n",
      "indie_rock: 1061\n",
      "indieheads: 114832\n",
      "Libertarian: 280908\n",
      "MarchAgainstTrump: 98384\n",
      "neoliberal: 557280\n",
      "NeverTrump: 829\n",
      "photography: 118274\n",
      "politics: 5033408\n",
      "PoliticsWithoutTheBan: 10\n",
      "seinfeld: 13204\n",
      "The_Donald: 3120209\n",
      "worldnews: 2428736\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of posts in each subreddit for both months\")\n",
    "print(\"Android: \" + str(Android))\n",
    "print(\"Archaeology: \" + str(Archaeology))\n",
    "print(\"AskTrumpSupporters: \" + str(AskTrumpSupporters))\n",
    "print(\"boardgames: \" + str(boardgames))\n",
    "print(\"Conservative: \" + str(Conservative))\n",
    "print(\"DCcomics: \" + str(DCcomics))\n",
    "print(\"food: \" + str(food))\n",
    "print(\"Futurism: \" + str(Futurism))\n",
    "print(\"geopolitics: \" + str(geopolitics))\n",
    "print(\"gunpolitics: \" + str(gunpolitics))\n",
    "print(\"headphones: \" + str(headphones))\n",
    "print(\"hockey: \" + str(hockey))\n",
    "print(\"indie_rock: \" + str(indie_rock))\n",
    "print(\"indieheads: \" + str(indieheads))\n",
    "print(\"Libertarian: \" + str(Libertarian))\n",
    "print(\"MarchAgainstTrump: \" + str(MarchAgainstTrump))\n",
    "print(\"neoliberal: \" + str(neoliberal))\n",
    "print(\"NeverTrump: \" + str(NeverTrump))\n",
    "print(\"photography: \" + str(photography))\n",
    "print(\"politics: \" + str(politics))\n",
    "print(\"PoliticsWithoutTheBan: \" + str(PoliticsWithoutTheBan))\n",
    "print(\"seinfeld: \" + str(seinfeld))\n",
    "print(\"The_Donald: \" + str(The_Donald))\n",
    "print(\"worldnews: \" + str(worldnews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the project, I want political subreddits, both with and without political biases.  So, for biased political subreddits, I am going to use \"Conservative\", \"Libertarian\" and \"neoliberal\".  For nonbiased political subreddits, I am going to use \"politics\" and \"worldnews\".  As a control, I will use non political subreddits.  I will use \"Android\", \"boardgames\" and \"hockey\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I want to find out the average length of posts.  Many of the posts are very short.  I want to use the longest posts I can while mantaining the 50,000 post goal.  Below, I calculated the average lengths and how many posts are greater than 50, 100, 150, 200, 250, and 300 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in Conservative     : 169622\n",
      "Average length of body              : 218.35662826755964\n",
      "number of posts over 50   characters: 122319\n",
      "number of posts over 100  characters: 91978\n",
      "number of posts over 150  characters: 69784\n",
      "number of posts over 200  characters: 54493\n",
      "number of posts over 250  characters: 43749\n",
      "number of posts over 300  characters: 35778\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(\"Number of posts in Conservative     : \" + str(num_posts))\n",
    "print(\"Average length of body              : \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50   characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150  characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300  characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of posts in Libertarian      : 280908\n",
      "Average length of body              : 287.30290344169623\n",
      "number of posts over 50   characters: 227488\n",
      "number of posts over 100  characters: 177428\n",
      "number of posts over 150  characters: 139855\n",
      "number of posts over 200  characters: 112474\n",
      "number of posts over 250  characters: 92363\n",
      "number of posts over 300  characters: 77299\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(\"Number of posts in Libertarian      : \" + str(num_posts))\n",
    "print(\"Average length of body              : \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50   characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150  characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300  characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557280\n",
      "Average length of body: 153.20315281366638\n",
      "number of posts over 50  characters: 350206\n",
      "number of posts over 100  characters: 221754\n",
      "number of posts over 150 characters: 150061\n",
      "number of posts over 200  characters: 108318\n",
      "number of posts over 250  characters: 82134\n",
      "number of posts over 300 characters: 64611\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5033408\n",
      "Average length of body: 202.61892399741885\n",
      "number of posts over 50  characters: 3629278\n",
      "number of posts over 100  characters: 2579653\n",
      "number of posts over 150 characters: 1897668\n",
      "number of posts over 200  characters: 1456237\n",
      "number of posts over 250  characters: 1155323\n",
      "number of posts over 300 characters: 941578\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2428736\n",
      "Average length of body: 200.97222794078894\n",
      "number of posts over 50  characters: 1691007\n",
      "number of posts over 100  characters: 1215445\n",
      "number of posts over 150 characters: 901245\n",
      "number of posts over 200  characters: 693553\n",
      "number of posts over 250  characters: 548246\n",
      "number of posts over 300 characters: 444789\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434356\n",
      "Average length of body: 182.29371529344593\n",
      "number of posts over 50  characters: 319113\n",
      "number of posts over 100  characters: 222110\n",
      "number of posts over 150 characters: 156447\n",
      "number of posts over 200  characters: 113629\n",
      "number of posts over 250  characters: 85317\n",
      "number of posts over 300 characters: 65906\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184762\n",
      "Average length of body: 254.62208138037042\n",
      "number of posts over 50  characters: 148076\n",
      "number of posts over 100  characters: 116951\n",
      "number of posts over 150 characters: 91284\n",
      "number of posts over 200  characters: 72144\n",
      "number of posts over 250  characters: 57927\n",
      "number of posts over 300 characters: 47144\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "843259\n",
      "Average length of body: 114.62820082560637\n",
      "number of posts over 50  characters: 501472\n",
      "number of posts over 100  characters: 285673\n",
      "number of posts over 150 characters: 179058\n",
      "number of posts over 200  characters: 120722\n",
      "number of posts over 250  characters: 86133\n",
      "number of posts over 300 characters: 63933\n"
     ]
    }
   ],
   "source": [
    "num_posts = 0\n",
    "num_chars = 0\n",
    "over_50 = 0\n",
    "over_100 = 0\n",
    "over_150 = 0\n",
    "over_200 = 0\n",
    "over_250 = 0\n",
    "over_300 = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "        \n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/August_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1   \n",
    "                           \n",
    "        num_posts = num_posts + 1\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        num_chars = num_chars + len(line_in['body'])\n",
    "        if len(line_in['body'])>=50:\n",
    "            over_50 = over_50 + 1\n",
    "        if len(line_in['body'])>=100:\n",
    "            over_100 = over_100 + 1\n",
    "        if len(line_in['body'])>=150:\n",
    "            over_150 = over_150 + 1\n",
    "        if len(line_in['body'])>=200:\n",
    "            over_200 = over_200 + 1\n",
    "        if len(line_in['body'])>=250:\n",
    "            over_250 = over_250 + 1\n",
    "        if len(line_in['body'])>=300:\n",
    "            over_300 = over_300 + 1            \n",
    "\n",
    "        num_posts = num_posts + 1\n",
    "\n",
    "print(num_posts)\n",
    "print(\"Average length of body: \" + str(num_chars/num_posts))\n",
    "print(\"number of posts over 50  characters: \" + str(over_50))\n",
    "print(\"number of posts over 100  characters: \" + str(over_100))\n",
    "print(\"number of posts over 150 characters: \" + str(over_150))\n",
    "print(\"number of posts over 200  characters: \" + str(over_200))\n",
    "print(\"number of posts over 250  characters: \" + str(over_250))\n",
    "print(\"number of posts over 300 characters: \" + str(over_300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to have atleast 50,000 posts from each subreddit, I will have to work with posts with lengths greater than 150 characters.  The subreddit with the least number of posts greater than 150 characters is \"Conservative\" with 69,784 posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'parent_id':[], \n",
    "     'author':[], \n",
    "     'distinguished':[], \n",
    "     'body':[], \n",
    "     'gilded':[], \n",
    "     'score':[], \n",
    "     'author_flair_css_class':[],\n",
    "     'stickied':[],\n",
    "     'retrieved_on':[],\n",
    "     'author_flair_text':[],\n",
    "     'id':[]\n",
    "    }\n",
    "\n",
    "x = 0\n",
    "\n",
    "temp_df = pd.DataFrame(data=d)\n",
    "\n",
    "t = '../../csv_files'\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Conservative.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "temp_df.to_csv(t + '/Conservative.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Libertarian.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/Libertarian.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/neoliberal.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "temp_df.to_csv(t + '/neoliberal.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/politics.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/politics.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/worldnews.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/worldnews.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/Android.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/Android.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/boardgames.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/boardgames.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = 0\n",
    "\n",
    "with open(\"../../Reddit_Data_trimmed/September_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "with open(\"../../Reddit_Data_trimmed/August_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "                x = x +1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "with open(\"../../Reddit_Data_trimmed/June_17/hockey.txt\", 'r') as file_in:\n",
    "    for line in file_in:\n",
    "        line_in = json.loads(line)\n",
    "        if x < 50000:\n",
    "            if len(line_in['body']) >= 150:\n",
    "                temp_df.loc[x, 'parent_id'] = line_in['parent_id']\n",
    "                temp_df.loc[x, 'author'] = line_in['author']\n",
    "                temp_df.loc[x, 'distinguished'] = line_in['distinguished']\n",
    "                temp_df.loc[x, 'body'] = line_in['body']\n",
    "                temp_df.loc[x, 'gilded'] = line_in['gilded']\n",
    "                temp_df.loc[x, 'score'] = line_in['score']\n",
    "                temp_df.loc[x, 'author_flair_css_class'] = line_in['author_flair_css_class']\n",
    "                temp_df.loc[x, 'stickied'] = line_in['stickied']\n",
    "                temp_df.loc[x, 'retrieved_on'] = line_in['retrieved_on']\n",
    "                temp_df.loc[x, 'author_flair_text'] = line_in['author_flair_text']\n",
    "                temp_df.loc[x, 'id'] = line_in['id']\n",
    "        else:\n",
    "            break\n",
    "\n",
    "temp_df.to_csv(t + '/hockey.csv', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
